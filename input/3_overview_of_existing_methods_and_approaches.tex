\section{Обзор существующих подходов к предсказанию масштабируемости}
%как свойства параллельной программы, характеризующего зависимость изменения всей совокупности динамических характеристик работы этой программы от множества параметров её запуска
	Когда говорят о предсказании масштабируемости, то рассматривают не всю совокупность динамических характеристик работы программы, а её часть. Большинство исследований направлены на предсказание времени исполнения программы в зависимости от параметров её запуска. Также существуют работы, рассматривающие предсказание производительности, ускорения, эффективности и энергопотребления. Однако этими характеристиками всё не ограничивается, так, например, в исследовании \cite{efficiency_prediction} авторы строят модель, предсказывающую несколько не совсем стандартных характеристик параллельной программы: первая отражает потенциальную потерю эффективности, вызванную различным временем вычислений разных процессов, вторая - неэффективность, вызванную зависимостями в коде, а третья - потерю производительности, вызванную передачей данных.
	%Ими также как и в \#LINK\# исследуется возможность предсказания данных характеристик приложения на больших конфигурациях, построенного на основе запусков на малых конфигурациях. \#мб результаты убрать\# Модель тестируется с помощью приложений из CORAL(HACC, Nekbone, AMG2013) и приложения AVBP. Запуски HACC и Nekbone проводятся в условиях сильной масштабируемости, а AMG2013 и AVBP - в условиях слабой. Получившиеся значения относительных ошибок варьируются от 0.01\% до 27.19\%.

	%Существует большое число работ направленных на исследование и предсказание масштабируемости приложений на суперкомпьютерах,
	Большинство работ направлено на исследование и предсказание масштабируемости приложений на суперкомпьютерах, но встречаются и такие, которые используют для запуска параллельных приложений отдельные узлы, небольшие вычислительные системы, грид-системы, платформы для облачных вычислений.

	Все исследования можно разделить на две группы: первая объединяется в себе те труды, которые ставят перед собой цель, используя запуски на малых конфигурациях, экстраполировать их результаты на большие; вторая же состоит из тех работ, которые, основываясь на результатах запусков, равномерно распределённых по пространству параметров, пытаются интерполировать их на всё пространство параметров.

	Наиболее распространёнными для предсказания масштабируемости являются подходы, использующие аппарат линейной регрессии, методы машинного обучения, а именно нейронные сети, симуляцию исполнения программы и коллаборативную фильтрацию. Все они будут рассмотрены в следующей части этой главы.

	\subsection{Линейная регрессия}
		В статье \cite{log_main} предложены 3 техники предсказания масштабируемости параллельных программ, в основе которых лежит подбор коэффициентов линейной регрессии. Эти техники используют набор запусков приложений на небольшом количестве процессов с разными входными парамерами, чтобы предсказать производительность на большом количестве процессов. Первая техника является идейно самой простой: результаты тестовых запусков используются для подбора коэффициентов регрессии, а затем с помощью построенной модели результаты экстраполируются на конфигурации большого размера. Вторая и третья техники являются усовершенствованиями первой, они обе рассматривают время вычислений и время коммуникаций отдельно. Отличия в том, что вторая техника основывается на временах вычислений и коммуникаций, полученных от каждого из процессов, выбирая максимальный по времени вычислений процесс и используя его же время коммуникаций, а третья техника основывается на определении времени коммуникаций и вычислений на критическом пути, самой длинной последовательности выполнения программы без блокировок.

		В статье рассматривается сильная масштабируемость, где это возможно, то есть, где задача помещается в память при выполнении на малом количестве процессов, или гибрид сильной и слабой масштабируемостей. Строятся предсказания времени выполнения программы на большом количестве процессов, используя несколько запусков той же программы на меньшем количестве. Для оценки качества предсказаний используется относительная ошибка. Из-за этого необходимо применять приближение в логарифмическом масштабе, а с учётом того, что авторами выбрана линейная регрессионная модель, формулу предиктора можно записать в виде:
		\[
		\log_2{(T)} = \sum_{i=1}^{n}{\beta_i \cdot \log_2{(x_i)}} + g(p) + error
		\]
		Где для выражения, объясняющего вклад количества используемых процессов выбирается либо линейное, либо квадратичное представление:
		\[
		g(p) = \gamma_0 + \gamma_1 \cdot \log_2(p) + [\gamma_2 \cdot log_2^2(p)]
		\]
		Несмотря на наличие логарифмов, статистически это всё ещё линейная модель, поскольку она линейна относительно неизвестных параметров.


		% \(p\) процессах, используя несколько запусков той же программы на \(q\) процессах, где \(q \in \{2,\ldots, p_0\},\,p_0 < p\), для произвольного \(p\). Предиктор реального времени исполнения \(T\) представляет собой функцию зависящую от входных параметров \((x_1, x_2, \ldots, x_n)\) и количества используемых процессов \(q\):
		% \begin{equation}\label{lin_formula}
		% \hat{T} = F(x_1, x_2, \ldots, x_n, q)
		% \end{equation}
		% Для оценки качества предсказаний используется относительная ошибка, вычисляемая по формуле:
		% \begin{equation}
		% E = \frac{|T - \hat{T}|}{T}
		% \end{equation}
		% Из-за того что используется относительная ошибка для оценки модели, \(F\) должная приближать \(T\) в логарифмическом масштабе, а с учётом того, что авторами используется линейная модель, формула \ref{lin_formula} преобразуется в
		% \begin{equation}
		% \log_2{(T)} = \sum_{i=1}^{n}{\beta_i\log_2{(x_i)}} + g(q) + error
		% \end{equation}
		% , где для выражения, объясняющего вклад количества используемых процессов используется либо линейное, либо квадратичное выражение:
		% \begin{equation}
		% g(q) = \gamma_0 + \gamma_1\log_2(q) + [\gamma_2log_2^2(q)]
		% \end{equation}
		% Несмотря на наличие логарифмов, статистически это всё ещё линейная модель, поскольку она линейна относительно неизвестных параметров.

		Для различных приложений медианная ошибка предсказаний изменяется от 1\% до 92\% в случае с первой техникой и от 7\% до 67\% для второй и третьей техник.

		Построенная модель обладает несколькими недостатками: не всегда возможно разделить время коммуникаций и вычислений, а чтобы это сделать, возможно, необходимо обладать знаниями об исходном коде программы или быть способным его модифицировать, поэтому использование второй и третьей техник не всегда представляется возможным. Также неясно, какой вид для функции \(g(q)\) следует выбрать. Дополнительно авторами метода прогнозирования предполагалось, что исследуемые задачи обладают хорошей вычислительной сбалансированностью, но далеко не все параллельные приложения отвечают этому предположению.

		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Такой же подход, использование линейной регрессии и логарифмической шкалы, применяется в работе \cite{focused_regression}. В ней авторы ставят перед собой задачу разработать модель, позволяющую находить конфигурации запуска так, чтобы они находились на кривой постоянного времени работы приложения, если в качестве пространства параметров конфигураций рассматривать размер задачи и количество процессов, на которых будет запущено приложение. Для построения модели используется информация о том, есть ли связь между параметрами запуска приложения, специфицируется ли при запуске процессорная сетка, позволяющая контролировать распределение данных, и набор запусков приложения на небольшим количестве процессов. Экспериментальная проверка построенной модели на семи суперкомпьютерных приложениях позволила предсказать неизвестные значения параметров так, что медианная ошибка предсказаний получилась меньше 13\%.

		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Подход, предложенный в \cite{analytic_func}, отличается от всех остальных прежде всего тем, что строятся не просто предсказания значений той или иной динамической характеристики параллельной программы, а предлагается функция, описывающая изменение этой характеристики и зависящая от параметров запуска. Такой подход находит своё применение, когда необходимо оценить асимптотику поведения динамических характеристик, но построение точной, аналитической модели является затруднительной задачей.
			
		На первом этапе работы собирается такая информация, как время исполнения, значения различных аппаратных (количество операций с числами с плавающей запятой) и программных (количество байт, которые MPI функции отправили и приняли) счётчиков производительности. Чтобы обеспечить статистически значимый набор данных о производительности, измерения для одних их тех же конфигураций запуска проводятся несколько раз. Собранные результаты запусков разделяются на две группы: в первой находятся запуски на небольших конфигурациях, на них основывается работа по подбору коэффициентов, во второй - запуски на конфигурациях большего размера, именно на них поведение приложений представляет наибольший интерес, использующиеся для оценки качества предсказаний модели. С помощью профайлера Scalasca в коде программы выделяются фрагменты, так называемые ядра, к которым можно отнести вызовы MPI функций и наиболее вычислительно интенсивные участи кода. Далее, используется регрессия для получения грубой модели производительности для каждого ядра. В качестве моделей рассматриваются выражения вида:
		\[
		f(p) = \sum \limits_{k=1}^{n} c_k \cdot p^{i_k} \cdot \log_2^{j_k}(p),\; i_k \in I,\; j_k \in J 
		\]
		Где \(I\) и \(J\) заданные заранее множества. Эти модели позднее проходят итеративный процесс уточнения, во время которого методами регрессионного анализа подбираются наиболее оптимальные значения \(c_k\) для всевозможных троек \(n,\;i_{k},\;j_{k}\), пока качество модели не достигнет точки насыщения. Если степень точности предсказаний недостаточна для получения действенной рекомендации, то исследуемые ядра могут быть дополнительно уточнены с помощью более подробного инструментария. Разработанный подход тестировался на приложениях SWEEP3D, MILC и предсказал асимптотики масштабируемости, в точности согласующиеся с ранее созданными точными моделями. Для приложения HOMME, масштабируемость которого раннее не исследовалась, и поэтому такой точной модели не было, предложенный авторами подход позволил обнаружить плохую масштабируемость одного из ядер, что затем полностью подтвердилось результатами проведённых экспериментов.

		Стоит отметить, что множества \(I\) и \(J\) задаются для каждого приложения по-своему, количество и значения элементов в них устанавливается исходя только из логических соображений, что не удовлетворяет требованиям универсальности, ведь результаты предсказаний напрямую зависят от человека, исследующего характеристики приложения и задающего эти множества.


	\subsection{Методы машинного обучения}
		Методы машинного обучения широко применяются для предсказания производительности параллельных приложений, так как построение точной аналитической модели приложения часто является очень затруднительным, а сами модели не способны уловить сложные аспекты взаимодействия между архитектурой суперкомпьютера и исследуемыми программами.

		В статье \cite{ML_SMG2000} трёхслойная полносвязная нейронная сеть прямого распространения с сигмоидой в качестве функции активации используется для предсказания времени работы приложения SMG2000. В процессе исследований авторы работы сталкиваются с двумя проблемами, из-за которых средняя ошибка предсказаний даже при использовании 10 тысяч запусков, равномерно распределённых по пространству параметров, в качестве обучающего множества, превосходит 15\%. Первая из проблем - это значительные шумы в результатах проведённых запусков, проявляющиеся в значительных падениях производительности. Они, например, могут возникать из-за работы операционной системы, использующей ресурсы вычислительного комплекса совместно с потоками исполнения приложения. В качестве способа преодоления этой проблемы авторы выбрали резервирование, как минимум, одного процесса на узле на нужды ОС. Вторая проблема является более серьёзной и не так просто преодолимой. Она заключается в ориентированности алгоритма подбора весов в нейронной сети на минимизацию среднего квадрата ошибки, в то время как качество предсказания оценивается по вычислениям относительных ошибок. Чтобы исправить это, применяются техники стратификации выборки с применением весов и беггинг для обучения ансамблей моделей и дальнейшего усреднения прогнозов. После осуществления вышеописанных изменений качество предсказаний значительно возрастает. Теперь при использовании 500 запусков средняя ошибка предсказаний не превышает 12\%, а при увеличении размера обучающей выборки в 5 раз, до 2500 запусков, авторы получают уменьшение средней ошибки до 6,5\%, что уже является достаточно высокой точностью.

		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Применение нейронных сетей не ограниченно предсказаниями производительности на классических HPC системах, так технологии машинного обучения используют в \cite{ML_Grid} для предсказания времени работы научных приложений, состоящих из нескольких подзадач со сложными внутренними зависимостями, на Grid системах. Моделирование и предсказание времён выполнения таких приложений очень сложно из-за распределения и параллельного исполнения подзадач на столь разнородной системе и динамического поведения общих Grid ресурсов. Ошибка предсказаний рассматриваемой в работе трёхслойной нейронной сети с радиально-базисной функцией, в качестве функции активации, в среднем не превышает 12\%. Но стоит отметить, что для обучения потребовалось 10000 запусков рассматриваемых в статье приложений.

		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Нейронную сеть такой же конфигурации, как в \cite{ML_SMG2000}, авторы \cite{ML_PROC_KERN} применют для предсказания наиболее оптимальных параметров запусков приложений на SMP системах. В качестве параметров рассматриваются количество процессоров и количество запрашиваемых ядер на одном процессоре. Поиск оптимальной конфигурации необходим, так как использование оптимальных параметров позволяет не только сократить время вычислений и, как следствие, увеличить производительность, но и уменьшить энергопотребление. Проведённые авторами эксперименты показали, что разработанная нейросеть позволяет достичь медианной ошибки предсказаний времени 7.5\% (для оценки используются показатели времени на предложенной нейросетью конфигурации и оптимальной конфигурации, найденной полным перебором).

	\subsection{Симуляция исполнения программы}
		Подход с использованием симуляции исполнения приложений является наиболее сложным в реализации. Он часто использует в своей работе информацию о структуре программы и о подробных технических характеристиках используемой системы, но, несмотря на это, подобные подходы встречаются.

		Так описанный в статье \cite{simulation_FASE} фреймворк FASE (The Fast and Accurate Simulation Environment) позволяет проводит симуляцию исполнений приложений на HPC системах. FASE предоставляет инструментарий для оценки производительности виртуально-прототипированных систем для своевременного и экономически эффективного определения идеальной конфигурации системы для конкретного набора приложений. Работа фреймворка состоит из двух этапов: сначала с помощью встроенных инструментов собирается некоторая характеристика рассматриваемого приложения, далее вводятся параметры системы (тип коммуникационной сети, сетевой протокол, информация об используемых процессорах, оперативной памяти), то есть создаётся некоторая модель системы. Если рассматривается производительность приложения на уже существующей системе и известны некоторые её характеристики, например, пропускная способность или среднее время задержки сети, то добавление этой информации на втором этапе позволит сделать предсказания FASE более точными. Полученные относительные ошибки предсказания времени выполнения приложения в большинстве случаев не превосходят 10\% для бенчмарка Sweep3D и 1\% для перемножения матриц (корректность проверяется посредством моделирования исполнения приложений на существующих системах и сравнения с результатами реальных запусков на них).
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Также существует техника детерминированного воспроизведения приложения, предложенная в \cite{representative_replay}. Она лежит в основе работы среды PHANTOM, реализованной авторами статьи. PHANTOM позволяет предсказать производительность и время исполнения приложения на конфигурации с большим количеством процессов, используя множественные запуски того же приложения, но на конфигурациях меньшего размера. Для построения прогноза производительности используется симуляция на основе трассировки. Общую схему работы этой среды можно описать так: вычисления и коммуникации разделяются, собираются их трассы, время последовательных вычислений измеряется для каждой отдельной группы процессов путём детерминированного воспроизведения процесса выполнения приложения. После этого разработанный авторами симулятор SIM-MPI по собранным трассам, по полученному на предыдущем этапе времени вычислений и по параметрам сети целевой системы предсказывает поведение различных операций коммуникации и время работы всего приложения.

		Для тестирования PHANTOM использовались шесть традиционных HPC платформ с различными конфигурациями и одна платформа облачных вычислений. Рассматривался большой набор бенчмарков: 6 ядер из NPB, 8 приложений из SPEC MPI2007, ASCI Sweep3D и NWChem. Максимальная относительная ошибка для PHANTOM на классических системах не превосходит 10\%, а для облачного сервиса - 7\%.

	\subsection{Коллаборативная фильтрация}
		Авторы \cite{UV_matrix} используют подход, основанный на коллаборативной фильтрации и \(UV\) факторизации матрицы, для предсказания времени исполнения параллельных приложений на гетерогенных системах. Коллаборативная фильтрация хорошо себя зарекомендовал и широко используется в рекомендательных системах для построения прогнозов. Основная идея предложенного подхода состоит в том, чтобы использовать собранные профили выполненных запусков приложения в качестве набора обучающих данных, а затем построить специальную матрицу для прогнозирования производительности на новой конфигурации. Количество строк в этой матрице равно количеству проведённых тестирований исследуемой программы. Столбцами являются как параметры запуска программы (количество доступной памяти, количество процессов), так и значения динамических характеристик исполнения программы, полученные после её завершения. В качестве прогнозируемых характеристик в работе рассматриваются минимальное, среднее и максимальное времена исполнения приложения на нескольких запусках с идентичными конфигурациями. Чтобы предсказать значения этих характеристик в интересуемой конфигурации, необходимо дополнить матрицу ещё одной строкой, заполнить в ней первые ячейки, отвечающие за параметры запуска, и произвести \(UV\) факторизацию полученной матрицы. После перемножения \(U\) и \(V\) результирующая матрица будет "<ближе"> всего к изначальной, в качестве меры близости используется среднеквадратичная ошибка, а незаполненные ранее ячейки будут содержать предсказанные значения времён исполнения.

		Для запусков приложений использовалась платформа для параллельных вычислений Apache Spark, время исполнения предсказывалось для трёх приложений: Shapelet Finding, Common Neighbor и WordCount. При использовании 70\% от всех конфигураций в качестве тестовой выборки среднее значение ошибки по трём приложениям не превосходит 20\%, при увеличении количества тестовых конфигураций до 90\% значение средней ошибки снижается до 8-12\%.

		Чтобы предложенный метод был применим, необходимо, чтобы исходная таблица обладала большим количеством строк и столбцом, то есть было проведено много тестирований программы и были доступны большие наборы параметров запуска программы и динамических характеристик исполнения.

	\subsection{Базовый подход к предсказанию масштабируемости}
		В работах \cite{Kazmina_Antonov_article} и \cite{Kazminf_Valkon_Antonov_article} рассматриваются все три вида масштабируемости: слабая, сильная и вширь. Предсказание динамических характеристик исполнения строятся для больших задач по результатам исполнения малых задач. В качестве динамической характеристики для всех видов масштабируемости выбрано время выполнения программы. Для построения прогноза в случае сильной масштабируемости и масштабируемости вширь используются экстраполирующие функции:
		\[
		T(p) = a \cdot p + b \cdot p^{-1} + c \cdot p^{-0.5},\;\text{для слабой масштабируемости}.
		\]
		\[
		T(s) = b \cdot (1 + a)^{s} + c,\;\text{для масштабируемости вширь}.
		\]
		Независимо от вида функции подбор регрессионных коэффициентов осуществляется с помощью алгоритма Левенберга-Марквардта, итеративного алгоритма оптимизации параметров нелинейных регрессионных моделей. Попытки построить предсказания с помощью подбора экстраполирующей функции в случае слабой масштабируемости не дают приемлемых результатов. Тем не менее, предсказания строятся при помощи объединения методов (поочерёдного применения) предсказаний сильной масштабируемости и масштабируемости вширь. Для пяти рассматриваемых приложений, HPL, NPB (BT, SP, LU) и Graph500, общая медианная относительная ошибка не превышает 23\%. 

		Также в данных работах предложен альтернативный применению логарифмической шкалы из \cite{log_main} и \cite{focused_regression} способ - использование регрессионной модели с весами, где под весом некоторого тестового запуска подразумевается количество его экземпляров, которые будут входить в итоговый сформированный набор запусков, по которым строится аппроксимация. Добавление весов направленно на устранение двух возможных причин увеличения ошибок предсказания: минимизацию абсолютных ошибок вместо относительных во время регрессии и одинаковую значимость ошибок для всех размеров конфигурации при действительной важности результатов предсказания только для конфигураций большего размера. Данный способ позволил уменьшить средние и медианные относительные ошибки предсказаний для всех рассматриваемых приложений.

		Предложенный в следующей главе метод перенимает многие идеи и принципы из работ \cite{Kazmina_Antonov_article} и \cite{Kazminf_Valkon_Antonov_article}, но лежащая в его основе математическая модель, с помощью которой строятся предсказания, отличается. Помимо этого, конфигурации запуска для построения предсказаний слабой масштабируемости выбираются строго согласно определению этого вида масштабируемости, такой набор конфигураций позволяет определить динамику изменения рассматриваемых динамических характеристик и, как следствие, построить более точные предсказания.

\clearpage
