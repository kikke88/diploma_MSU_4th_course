\chapter{Введение}
	ЧЕРНОВИК

	Без параллельных технологий сейчас невозможно обойтись во многих прикладных областях науки: гидро- и аэро- динамике, квантовая химии, сейсмике, компьютерном моделировании лекарств, криптографии и многих других. Это связано с необходимостью обрабатывать большие объёмы данных и производить колоссальное количество вычислений. Что стимулирует проектирование больших суперкомпьютерных центров, развитие технологий конструирования аппаратных комплектующих, разработку новых методик и алгоритмов.

	Если используемые пакеты прикладных программ и научные приложения будут плохо написаны, выбранный алгоритм слабо параллелизуем или неоптимально реализован в коде, то они не смогут в полной мере использовать вычислительные ресурсы, продоставляемые высокопроизводительным центром. Если рассмотреть результеты запусков бенчмарков HPL и HPCG на суперкомпьютерах из рейтенга TOP500 \cite{top500}, то окажется, что для HPL среднее отношение реальной и пиковой производительностей около 63.5\%, для HPCG этот показатель сильно ниже - около 1.5\%(результаты тестирования HPCG предоставлены только для 70 суперкомпьютеров).\#АКТУАЛЬНО но 16 марта\# Данные бенчмарки - это сверх оптимизированные приложения, написанные в тесном сотрудничестве математиками и программистами, лишь малая часть параллельных программ имеют схожую степень параллелизуемости.
	ДАННЫЕ ОБ ИСПОЛЬЗОВАНИИ ЛОМОНОСОВА1-2

	% фундаментальные ограничения, как закон Амдала и закон Густавсона — Барсиса,

	%Поэтому так важно иметь метрику, способную описать, как конфигурация системы и размер задачи влияют на производительность суперкомпьютеров и параллельных алгоритмов.

	Существует множество характерискик работы параллельных программ, например, время её выполнения, ускорение и эффективность, производительность, количество обращений в память и кэш-промахов. Так как все они имеют динамическую сущность, то есть могут изменяться от запуска к запуску, зависят от параметров запуска программы и машины, на которой она выполняется, назовём их динамическими характеристиками параллельной программы.

	Чтобы понять свойства параллельных программ и причины найденных в них особенностей, нужно рассматривать все доступные динамические характеристики на всём пространстве параметров запуска. Этот задача напрямую связана с понятием "<масштабируемость">, свойством параллельной программы, характеризующим зависимость изменения всей совокупности динамических характеристик работы этой программы от множества параметров её запуска \cite{scalability_def}.

	Здесь и далее обозначим: \(p\) - количество процессов, на которых запущено приложение; \(N\) - размера задачи; \(T_A(N)\) - временная сложность алгоритма \(А\) для значения \(N\) размера входа. \(T_A(N) = \max_{||y|| = N}C^T_A(y)\) \#LINK\#, где \(C^T_A(y)\) сложность %временные затраты 
	алгоритма \(А\) для входа \(y\). Временную сложность алгоритма следует понимать, как последовательную сложность, то есть, как число операций, которое нужно выполнить при последовательном выполнении алгоритма.

	Во время исследования масштабируемости приложения необходимо указывать, на какой области изменения значений параметров проведены запуски. По выбору параметров запуска, которые будут изменяться, масштабируемость согласно \cite{scaling_types} можно разделить на три основных типа:
	\begin{itemize}
		\item Сильная масштабируемость (strong scaling) - зависимость производительности от количества процессов \(p\) при фиксированной вычислительной сложности задачи задачи \((T_A(N) = const \Rightarrow N = const)\).
		\item Слабая масштабируемость (weak scaling) - зависимость производительности от количества процессов \(p\) при фиксированной вычислительной сложности задачи в пересчете на один узел \((T_A(N)\:/\:p = const)\)
		\item Масштабируемость вширь (wide scaling) - зависимость производительности от размера задачи при фиксированном количестве процессов \((p = const)\)
	\end{itemize}


	Масштабируемость - ключевое понятние в вопросах исследования свойств параллельных программ, поэтому крайне важно учитывать её на всех этапах разработки программного обеспечения. Однако не всегда возможно получить в распряжение большое количество узлов, чтобы увидеть характер изменения различных динамических характеристик приложения с ростом числа используемых узлов, или ожидание этого может занять непозволительно много времени, например, авторы статьи \cite{log_main} утверждают, что в худшем случае время ожидания выделения необходимого количества узлов растёт экспоненциально с ростом количества запрашиваемых ресурсов системы. Но ведь именно возможноть решать задачи больших размеров за разумное время, используя большое количество узлов, является главным преимуществом суперкомпьютерных систем, поэтому необходимо, чтобы приложение было хорошо масштабируемо. Обычно пользователь может выполнить задачу на небольшой конфигурации быстрее, чем запустить на большом количестве узлов. Исходя из этого, актуальна задача прогнозирования масштабируемости приложения на большие конфигурации вычислительной системы, без доступа к его коду и возможности его изменять, основываясь только на данных, полученных из множественных запусков на малых конфигурациях. В данной работе предлагается механизм решения поставленной задачи в условиях слабой масштабируемости суперкомьютерных приложений.

%\clearpage