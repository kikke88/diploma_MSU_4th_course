\section{Введение}
	Без параллельных технологий сейчас невозможно обойтись во многих прикладных областях науки: гидро- и аэро- динамике, квантовой химии, сейсмике, компьютерном моделировании лекарств, криптографии и многих других. Это связано с необходимостью обрабатывать большие объёмы данных и производить колоссальное количество вычислений. Что стимулирует создание больших суперкомпьютерных центров, развитие технологий конструирования аппаратных комплектующих, разработку новых методик и алгоритмов.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ЕСЛИ ЕСЛИ
	Если используемые пакеты прикладных программ и научные приложения будут плохо написаны, выбранный алгоритм слабо параллелизуем или неоптимально реализован в коде, то они не смогут в полной мере использовать вычислительные ресурсы, предоставляемые высокопроизводительным центром. Если рассмотреть результаты запусков бенчмарков HPL и HPCG на суперкомпьютерах из рейтинга TOP500 \cite{top500}, то окажется, что для HPL среднее отношение реальной и пиковой производительностей среди всех суперкомпьютеров рейтинга около 63.5\%, для HPCG этот показатель сильно ниже - около 1.5\% (результаты тестирований HPCG предоставлены только для 70 суперкомпьютеров). Данные бенчмарки - это сверх оптимизированные приложения, написанные большими коллективами математиков и программистов, лишь малая часть программ имеют схожую степень параллелизуемости. В статье \cite{Perf_low} приводятся данные с производительностью реальных научных приложений (моделирование распространения сейсмических волн, высокотемпературной плазмы, термоядерного синтеза) на суперкомпьютере Blue Water из Университета Иллинойса. По всем приложениям производительность не превышает 20\% от пиковой.

	Существует множество характеристик работы параллельных программ, например, время её выполнения, ускорение, эффективность, производительность, количество обращений в память и кэш-промахов. Все эти характеристики имеют динамическую сущность, то есть могут изменяться от запуска к запуску, зависят от параметров запуска программы и машины, на которой она выполняется. Поэтому будем называть их динамическими характеристиками параллельной программы.

	Чтобы определить свойства параллельных программ и причины найденных в них особенностей, нужно рассматривать все доступные динамические характеристики на всём пространстве параметров запуска. Эта задача напрямую связана с понятием "<масштабируемость">, свойством параллельной программы, характеризующим зависимость изменения всей совокупности динамических характеристик работы этой программы от множества параметров её запуска \cite{scalability_def}.

	Здесь и далее обозначим: \(p\) - количество процессов, на которых запущено приложение; \(N\) - размера задачи; \(T_A(N)\) - сложность алгоритма \(А\) для значения \(N\) размера входа. \(T_A(N) = \max_{||y|| = N} C^T_A(y)\), где \(C^T_A(y)\) сложность алгоритма \(А\) для входа \(y\) \cite{COMPLEXITY}. Сложность алгоритма следует понимать, как последовательную сложность, то есть, как число операций, которое нужно выполнить при последовательном выполнении алгоритма.

	Во время исследования масштабируемости приложения необходимо указывать, на какой области изменения значений параметров проводятся запуски. По выбору параметров запуска, которые будут изменяться, масштабируемость согласно \cite{scaling_types} можно разделить на три основных типа:
	\begin{itemize}
		\item Сильная масштабируемость (strong scaling) - зависимость динамических характеристик от количества процессов при фиксированной вычислительной сложности задачи \((T_A(N) = const \Rightarrow N = const)\).
		\item Слабая масштабируемость (weak scaling) - зависимость динамических характеристик от количества процессов при фиксированной вычислительной сложности задачи в пересчете на один процесс \((T_A(N)\:/\:p = const)\).
		\item Масштабируемость вширь (wide scaling) - зависимость динамических характеристик от размера задачи при фиксированном количестве процессов \((p = const)\).
	\end{itemize}

	Масштабируемость - ключевая характеристика параллельных программ. Крайне важно учитывать её во время исследования свойств этих программ или в процессе их разработки.
	Однако не всегда возможно получить в распоряжение большое количество узлов, чтобы увидеть характер изменения различных динамических характеристик приложения с ростом числа используемых ресурсов системы, при увеличении размера задачи. Так же ожидание этого может занять непозволительно много времени, например, авторы статьи \cite{log_main} утверждают, что в худшем случае время ожидания выделения необходимого количества узлов растёт экспоненциально с ростом количества запрашиваемых ресурсов. Но ведь именно возможность решать за разумное время задачи больших размеров, используя большое количество узлов, является главным преимуществом суперкомпьютерных систем, поэтому необходимо, чтобы приложение было хорошо масштабируемо. Обычно пользователь может выполнить задачу на небольшой конфигурации быстрее, чем запустить на большом количестве узлов. Исходя из этого, актуальна задача прогнозирования масштабируемости приложения на большие конфигурации вычислительной системы, основываясь только на данных, полученных из множественных запусков на малых конфигурациях.
	%На разрабатываемый метод накладываются условия универсальности, то есть для своей работы он не должен использовать информацию о коде, алгоритме и системе на которой производятся запуски.
	В этой работе предлагается метод решения поставленной задачи в условиях слабой масштабируемости суперкомпьютерных приложений.

\clearpage
%\newpage