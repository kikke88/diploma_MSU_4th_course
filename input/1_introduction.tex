\section{Введение}
	Без параллельных технологий сейчас невозможно обойтись во многих прикладных областях науки: гидро- и аэро- динамике, квантовая химии, сейсмике, компьютерном моделировании лекарств, криптографии и многих других. Это связано с необходимостью обрабатывать большие объёмы данных и производить колоссальное количество вычислений. Что стимулирует создание больших суперкомпьютерных центров, развитие технологий конструирования аппаратных комплектующих, разработку новых методик и алгоритмов.

	Если используемые пакеты прикладных программ и научные приложения будут плохо написаны, выбранный алгоритм слабо параллелизуем или неоптимально реализован в коде, то они не смогут в полной мере использовать вычислительные ресурсы, предоставляемые высокопроизводительным центром. Если рассмотреть результаты запусков бенчмарков HPL и HPCG на суперкомпьютерах из рейтинга TOP500 \cite{top500}, то окажется, что для HPL среднее отношение реальной и пиковой производительностей около 63.5\%, для HPCG этот показатель сильно ниже - около 1.5\%(результаты тестирования HPCG предоставлены только для 70 суперкомпьютеров). Данные бенчмарки - это сверх оптимизированные приложения, написанные в тесном сотрудничестве математиками и программистами, лишь малая часть параллельных программ имеют схожую степень параллелизуемости. В статье \cite{Perf_low} приводятся данные с достигаемой производительностью на реальных научных приложениях, моделирование распространения сейсмических волн, высокотемпературной плазмы, термоядерного синтеза, на суперкомпьютере Blue Water из Университета Иллинойса, по всем приложениям производительность не превышает 20\% от пиковой.
	% фундаментальные ограничения, как закон Амдала и закон Густавсона — Барсиса,

	Существует множество характеристик работы параллельных программ, например, время её выполнения, ускорение и эффективность, производительность, количество обращений в память и кэш-промахов. Все они имеют динамическую сущность, то есть могут изменяться от запуска к запуску, зависят от параметров запуска программы и машины, на которой она выполняется, поэтому будем называть их динамическими характеристиками параллельной программы.

	Чтобы понять свойства параллельных программ и причины найденных в них особенностей, нужно рассматривать все доступные динамические характеристики на всём пространстве параметров запуска. Эта задача напрямую связана с понятием "<масштабируемость">, свойством параллельной программы, характеризующим зависимость изменения всей совокупности динамических характеристик работы этой программы от множества параметров её запуска \cite{scalability_def}.

	Здесь и далее обозначим: \(p\) - количество процессов, на которых запущено приложение; \(N\) - размера задачи; \(T_A(N)\) - сложность алгоритма \(А\) для значения \(N\) размера входа. \(T_A(N) = \max_{||y|| = N} C^T_A(y)\), где \(C^T_A(y)\) сложность алгоритма \(А\) для входа \(y\) \cite{COMPLEXITY}. Сложность алгоритма следует понимать, как последовательную сложность, то есть, как число операций, которое нужно выполнить при последовательном выполнении алгоритма.

	Во время исследования масштабируемости приложения необходимо указывать, на какой области изменения значений параметров проведены запуски. По выбору параметров запуска, которые будут изменяться, масштабируемость согласно \cite{scaling_types} можно разделить на три основных типа:
	\begin{itemize}
		\item Сильная масштабируемость (strong scaling) - зависимость динамических характеристик от количества процессов \(p\) при фиксированной вычислительной сложности задачи \((T_A(N) = const \Rightarrow N = const)\).
		\item Слабая масштабируемость (weak scaling) - зависимость динамических характеристик от количества процессов \(p\) при фиксированной вычислительной сложности задачи в пересчете на один узел \((T_A(N)\:/\:p = const)\)
		\item Масштабируемость вширь (wide scaling) - зависимость динамических характеристик от размера задачи при фиксированном количестве процессов \((p = const)\)
	\end{itemize}

	Масштабируемость - ключевое понятие в вопросах исследования свойств параллельных программ, поэтому крайне важно учитывать её на всех этапах разработки программного обеспечения. Однако не всегда возможно получить в распоряжение большое количество узлов, чтобы увидеть характер изменения различных динамических характеристик приложения с ростом числа используемых ресурсов системы, при увеличении размера задачи, или ожидание этого может занять непозволительно много времени, например, авторы статьи \cite{log_main} утверждают, что в худшем случае время ожидания выделения необходимого количества узлов растёт экспоненциально с ростом количества запрашиваемых ресурсов. Но ведь именно возможность решать задачи больших размеров за разумное время, используя большое количество узлов, является главным преимуществом суперкомпьютерных систем, поэтому необходимо, чтобы приложение было хорошо масштабируемо. Обычно пользователь может выполнить задачу на небольшой конфигурации быстрее, чем запустить на большом количестве узлов. Исходя из этого, актуальна задача прогнозирования масштабируемости приложения на большие конфигурации вычислительной системы, основываясь только на данных, полученных из множественных запусков на малых конфигурациях. В данной работе предлагается механизм решения поставленной задачи в условиях слабой масштабируемости суперкомпьютерных приложений.
\clearpage
%\newpage