%Разработка метода прогнозирования слабой масштабируемости суперкомпьютерных приложений

\chapter{Обзор существующие методов и подходов к предсказанию масштабируемости}

	??

	В основе работы метода предсказания из \cite{UV_matrix} лежит метод UV факторизации матрицы, который также часто используют в рекомендательных системах. Количество строк в этой матрице равно количеству проведённых тестированний исследуемой программы, столбцами являются как параметры запуска программы, такие как количество доступной памяти, количество процессов, на которых исполняется программа, и другие, так и значения характеристик исполнения программы, полученные после её завершения, в работе рассматривается минимальное, среднее и максимальное времена исполнения приложения по нескольким запускам в идентичных конфигурациях. Чтобы предсказать значения этих характеристик в интересуемой конфигурации необходимо дополнить матрицу ещё одной строкой, заполнить в ней первые ячейки, отвечающие за параметры запуска, и произвести UV факторизацию полученной матрицы. После перемножения U и V полученная матрица будет "ближе"\ всего к изначальной матрице, в качестве меры "близости"\ используется среднеквадратичная ошибка, а незаполненный ранее ячейки будут содержать предсказанные значения времён исполнения.

	Для запусков приложений использовалась платформа для параллельных вычислений Apache Spark, время исполнения предсказывалось для трёх приложений: Shapelet Finding , Common Neighbor и WordCount. При использовании 70\% от всех конфигураций в качестве тестовой выборки среднее значение ошибки по трём приложениям не превосходит 20\%, при увеличении количества тестовых конфигураций до 90\% значение средней ошибки снижается до 8-12\%.


	??

	... не только время и производительность. Так, например, в работе \cite{efficiency_prediction} авторы строят модель, предсказывающую несколько свойств параллельной программы: первое отражает потенциальную потерю эффективности, вызванную различными временами вычислений разных процессах, второе - неэффективность, вызванную зависимостями в коде, а третье - потерю производительности, вызванную передачей данных. Ими также как и в \#link\# исследуется возможность предсказания данных характеристик приложения на больших конфигурациях, построенного на основе запусков на малых конфигурациях. %мб результаты убрать
	Модель тестируется с помощью приложений из CORAL(HACC, Nekbone, AMG2013) и приложения AVBP. Запуски HACC и Nekbone проводятся в условиях сильной масштабируемости, а AMG2013 и AVBP - в условиях слабой. Получившиеся значения относительных ошибок варьируются от 0.01\% до 27.19\%.


	% \begin{itemize}
	% 	\item Load Balance efficiency отражает потенциальную потерю эффективности, вызванную различными временами вычислений разных процессах,
	% 	\item Serialization efficiency отражает неэффиктивность, вызванную зависимостями в коде.
	% 	\item Transfer efficiency отражает потерю производительности, вызванную передачей данных.
	% \end{itemize}
	\section{Регрессия}
		\subsection{Линейная}

Подход предложенный в \cite{analytic_func} отличается от всех остальных прежде всего тем, что строится не просто предсказания значений той или иной характеристики параллельной программы, а предлагается функция, описывающая изменение этой характеристики и зависящая от параметров запуска. Такой подход находит своё применение, когда необходимо оценить ассимптотику поведения характеристики, но построить точную аналитическую модель предсказаний является затруднительно.%это является более универсальным приёмом
	
На первом этапе работы собирается такая информация как время исполнения, значения различных счётчиков производительности, включая аппаратные счётчики(количество операций с чистами с плавающей точкой), программые счётчики(количество байт, которые MPI функции отправили и приняли). Чтобы обеспечить статистически значимый набор данных о производительности, измерения, для одних их тех же конфигураций запуска проводятся несколько раз. \label{several_times_test}%мб тут можно сказать, что может пойти не так%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
С помощью профайлера Scalasca в коде программы выделяются фрагменты, так называемые ядра, к которым можно отнести, вызовы MPI функций, наиболее вычислетильно интенсивные участи кода. Далее используется регрессия для получения грубой модели производительности для каждого ядра. В качестве моделей рассматриваются выражения вида:
\begin{equation}
f(p) = \sum \limits_{k=1}^{n} c_k \cdot p^{i_k} \cdot \log_2^{j_k}(p),\; i_k \in I,\; j_k \in J 
\end{equation}, где \(I\) и \(J\) заданные заранее множества. Эти модели затем проходят итеративный процесс уточнения, во время которого методами регрессионного анализа подбираются наиболее оптимальные значения \(c_k\) для всевозможных значений \(n,\;i_{k},\;j_{k}\), пока качество модели не достигнет точки насыщения. Собранные результаты запусков разделяются на две группы: в первой находятся запуски на небольших конфигурациях, на них основывается работа по подбору коэффициентов, во второй \- запуски на конфигурациях большего размера, именно она них поведение приложений представляет наибольший интерес, использующиеся для оценки качетсва предсказаний модели. Если степень точности предсказаний недостаточна для получения действенной рекомендации измерения производительности, то исследуемые ядра могут быть дополнительно уточнены с помощью более подробного инструментария. Разработанный подход тестировался на приложениях SWEEP3D, MILC и предсказал ассимптотики масштабируемости в точности согласующиеся с ранее созданными точными моделями. Для приложения HOMME, масшатибуемость которого раннее не исследовалась и поэтому такой точной модели не было, предложенный авторами подход позволил обнаружить плохую масштабируемость, что полностью подтвердилось результатами проведённых экспериментов.

(((((((((((((())))))))))))))

Такой же подход, использование линейной регрессии и логарифмической шкалы, применяется в работе \cite{focused_regression}. В ней авторы ставят перед собой задачу разработать модель, позволяющую предсказать параметры запуска приложения так, чтобы сохранялось его время работы, но при условии увеличении числа используемых процессов. Для построения модели используется информация о том, есть ли связь между параметрами запуска приложения, специфицируется ли при запуске процессорная сетка, позволяющая контролировать распределение данных, и набор запусков приложения на небольшим количестве процессов. Экспериментальная проверка построенной модели на семи суперкомпьютерных приложениях позволила предсказать неизвестные значения параметров, целевой конфигурацией во всех случаях были 1024 процесса, так что медианная ошибка предсказаний получилась меньше 13\%.




(((((((((((((())))))))))))))

В статье \cite{log_main} предложены 3 техники предсказания масшатабиремости параллельных программ, в основе которох лежит подбор коэффициентов с помощью линейной регрессии. Эти техники испольльзуют набор запусков приложений на небольшом количестве процессов с разными входными парамерами, чтобы предсказать производительность на большом количестве процессов. Первая техника является идейно самой простой: результаты тестовых запусков используются для подбора коэффициентов регрессии, а затем результаты экстраполируются на конфигурации большого размера. Две другие техники являются усовершенствованием первой, они обе рассматривают время вычислений и время коммуникаций отдельно, но если вторая техника основывается на временах вычислений и коммуникаций полученных от каждого из процессов, выбираяся максимальный по времени вычислений процесс и используется его же время коммуникаций, то третья техника основывается на определении времени коммуникаций и вычислений на критическом пути, самой длинной последовательности выполнения программы без блокировок.


Исследуется сильная масштабируемость, где это возможно, то есть где где задача помещается в память при использовании малого количества процессов, или гибрид сильной и слабой масштабируемостей. Строятся предсказания время выполнения программы на \(p\) процессах, используя несколько запусков той же программы на \(q\) процессах, где \(q \in \{2,\ldots, p_0\},\,p_0 < p\), для произвольного \(p\). Предиктор реального времени исполнения \(T\) представляет собой функцию зависящую от входных параметров \((x_1, x_2, \ldots, x_n)\) и количества используемых процессов:
\begin{equation}\label{lin_formula}
\hat{T} = F(x_1, x_2, \ldots, x_n, q)
\end{equation}
Для оценки качества предсказаний используется относительная ошибка, вычисляемая по формуле:
\begin{equation}
E = \frac{|T - \hat{T}|}{T}
\end{equation}
Из-за того что используется относительная ошибка для оценки модели, \(F\) должная приближать \(T\) в логарифмическом масштабе, и с учётом того, что авторами используется линейная модель, формула \ref{lin_formula} преобразуется в
\begin{equation}
\log_2{(T)} = \sum_{i=1}^{n}{\beta_i\log_2{(x_i)}} + g(q) + error
\end{equation}
, где для выражения, объясняющего вклад количества используемых процессов используется либо линейная, либо квадратичная модель:
\begin{equation}
g(q) = \gamma_0 + \gamma_1\log_2(q) + [\gamma_2log_2^2(q)]
\end{equation}
Несмотря на наличие логарифмов, статистически это всё ещё линейная модель, поскольку она линейна относительно неизвестных параметров.

Для различных приложений медианная ошибка предсказаний изменяется от 1\% до 92\% в случае с первой техникой и от 7\% до 67\% для второй и третьей техник. Однако используемая модель обладает несколькими недостатками: не всегда возможно разделить время коммуникаций и вычислений, а чтобы это сделать, возможно, необходимо обладать знаниями об исходном коде программы или быть способным его модифицировать, поэтому использование второй и третьей техник не всегда представляется возможным, при использовании этих техник также неясно, какой вид для функции \(g(q)\) следуеть использовать, авторами метода прогнозирования предполагалось, что исследуемые задачи обладают хорошей вычислительной сбалансированностью, но далеко не все параллельные приложения отвечают этому предположению.


% \begin{figure}[t]
% \centering
% \includegraphics[width=0.9\textwidth]{log_scale_res}
% \caption{Результаты предсказаний, рассмотренные в \cite{log_main} и использующие линейную регрессию}
% \label{log_main_res}
% \end{figure}

% Результаты экспериментов показали, что для трёх рассматриваемых приложений лучше использовать функцию \(g(q)\) линейно зависящую от логарифма, в то время как для четырёх других - квадратично(Type(Best) в \ref{log_main_res}). Так же стоить отметить, что использование 2 и 3 техник в некоторых случаях позволяют улучшить результат предсказаний в 4 раза(Median Error, Total/Separate  в \ref{log_main_res}).


		\subsection{Полиномиальная и иная}
	\section{Методы машинного обучения}
	Методы машинного обучения широко применяются для предсказания производительности параллельных приложений, так как построение точной аналитической модели приложения часто является очень затруднительным, а сами модели не способны уловить сложные аспекты взаимодействия между архитектурой суперкомпьютера и исследуемыми программами.

	В статье \cite{ML_SMG2000} трёхслойная полносвязная нейронная сеть прямого распространения с сигмоидой в качестве функции активации используется для предсказания времени работы приложения SMG2000. В процессе исследований авторы работы сталкнулись с двумя проблемами, из-за которых средняя ошибка предсказаний, даже при использовании 10 тысяч запусков, равномерно распределённых по пространству параметров, в качестве обучающего множества, превосходит 15\%. Первая из проблем - это значительные шумы в результатах проведённых запуском, проявляющиеся в значительных просадках производительности. Они, например, могут возникать из-за работы операционной системы, использующей ресурсы системы совместно с потоками исполнения приложения. В качестве способа преодоления этой проблемы авторами было выбрано резервирование как минимум одного процессе на узле на нужды ОС. Вторая проблема является более серьёзной и не так просто преодолимой. Это ориентированность алгоритма подбора весов в нейронной сети на минимизацию среднего квадрата ошибки, в то время как качество предсказания оценивается по вычислениям относительных ошибок. !!link сюда когда буду говорить про ошибки!!
	Чтобы исправить это понадобилось применить техники стратификации выборки с применением весов и беггинг для обучения ансамблей моделей и дальнейшего усреднения прогнозов. После проведения вышеописанных изменений качество предсказаний значительно возрасло, теперь при использовании всего 500 запусков, средняя ошибка предсказаний не превышает 12\%, однако при увеличении размера обучающей выборки в 5 раз, до 2500 запусков, авторы получили уменьшения средней ошибки до 6,5\%, что уже является достаточно высокой точностью.


	Примененеие нейронных сетей не ограниченно предсказаниями производительности на классических HPC системых, так авторы \cite{ML_Grid} используют технологии машинного обучения для предсказания времени работы научных приложений стостоящих из нескольких подзадач с сложными внутренними зависимостями на Grid системах. Моделирование и предсказание времён исполнения таких приложений на Grid системах очень сложно из-за распределения и параллельного исполнения подзадач на гетерогенной системе и динамического поведения общих Grid ресурсов. Ошибка предсказаний рассматриваемой в работе трёхслойная нейронной сети с радиально-базисной функцией, в качестве функции автивации в скрытов слое, в среднем не превышает 12\%, но стоит отметить, что для обучения нейронной сети потребовалось 10000 запусков рассмативаемых в статье приложений.

	Нейронную сеть такой же конфигурации, как в \cite{ML_SMG2000}, авторы \cite{ML_PROC_KERN} используют для предсказания наиболее оптимальных параметров запусков приложений на SMP системах. В качестве параметров рассматриваются количество процессоров и количество используемых ядер на одном процессоре. Использование таких оптимальных параметров позволяет не только сократить время вычислений и, как следствие, увиличить производительность, но и уменьшить энергопотребление. Эксперименты показали, что медианная ошибка предсказания времени составила 7.5\%.



	\section{Симуляция исполнения программы}

	
	Описанный в статье \cite{simulation_FASE} фреймворк FASE (The Fast and Accurate Simulation Environment) позволяет проводит симуляцию исполнений приложений на HPC системах. 
	%Фреймворк в первую очередь предназначеннен для облегчения проектирования системы в соответствии с потребностями одного или нескольких ключевых приложений.
	FASE предоставляет инструментарий для оценки производительности виртуально-прототипированных систем для своевременного и экономически эффективного определения идеальной конфигурации системы для конкретного набора приложений. Работа вреймворка состоит из двух этапов: сначала с помощью встроенных инструментов и методов собирается некоторая характеристика рассматриваемого приложения. Далее вводятся параметры системы (тип коммуникационной сети, сетевой протокол, информация об используемых процессорах, оперативной памяти),	то есть создаётся некоторая модель системы. Если рассматривается производительность приложения на уже существующей системе и известны некоторые её характеристики, например, пропускная способность или среднее время задержки сети, то при добавлении этой информации на втором этапе, предсказания FASE станут только точней. Полученные относительные ошибки моделируемого времени выполнения приложения в большинстве случаев не превосходят 10\% для бенчмарка Sweep3D и 1\% для перемножения матриц (корректность проверяется посредством моделирования исполнения приложений на существующих системах и сравнения с результатами реальных запусков на них).

	(((((((((((())))))))))))
	
	Также существует техника детерминированного воспроизведения приложения \cite{representative_replay}. Она лежит в основе работы среды PHANTOM, реализованной авторами статьи. PHANTOM позволяет предсказать производительность и время исполнения приложения на конфигурации с большим количеством процессов использую множественные запуски того же приложения, но на конфигурациях меньшего размера. Для построения прогноза производительности используется подход симуляции на основе трассировки. Общую схему работы этой среды можно описать так: вычисления и коммуникации разделяются, собираются их трассы, времена последовательных вычислений для каждого отдельного процесса путём выполнения на узле целевой системы при помощи разработанный техники детерминированного воспроизведения(representative replay авт.) процесса выполнения приложения. Из-за того что вычислений в параллельных приложениях демонстрирует большое сходство не только внутри каждого процеса, но и между различными процессами, можно объединить процессы в несколько групп, где процессы из одной группы имеют похожее поведение вычислений и проводить симуляцию воспроизведение только на одном процессе из группы. После этого разработанный авторами симулятор SIM-MPI по собранным трассам, полученному на этапе representative replay времени вычислений и параметрам сети целевой системы предсказывает поведения различные операций коммуникации и время работы всего приложения.

	Для тестирования PHANTOM использовались шесть традиционных HPC платформ с различными конфигурациями системы, Nebulae, Dawning, DeepComp-F, DeepComp-B, Explorer и Explorer-100 и одна платформа облачных вычислений Amazon EC2. Рассматривался большой набор бенчмарков: 6 ядер из NPB(Class E), 8 приложений из SPEC MPI2007(medius-size), ASCI Sweep3D(512 * 512 * 200) и NWChem. Максимальная относительная ошибка для PHANTOM на классических системах не превосходит 10\%, а для Amazon EC2 \- 7\%.
	% какая-то ерунда с \times


	\section{Сказать про Кристинину работу}
\clearpage

