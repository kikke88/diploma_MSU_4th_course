\chapter{Обзор существующие методов и подходов к предсказанию масштабируемости}
%как свойства параллельной программы, характеризующего зависимость изменения всей совокупности динамических характеристик работы этой программы от множества параметров её запуска
	Когда говорят о предсказании масштабируемости\#REF\#, то рассматривают не всю "<совокупность динамических характерискик работы"> программы, а её часть. Большинство исследований направлены на предсказание времени исполнения программы в зависимости от параметров её запуска, но также существуют другие, направленные на предсказание производительности, ускорения и эффективности, энергопотребления. Однако этими характеристиками всё не ограничивается, так, например, в работе \cite{efficiency_prediction} авторы строят модель, предсказывающую несколько не совсем стандартных характеристик параллельной программы: первая отражает потенциальную потерю эффективности, вызванную различными временами вычислений разных процессов, вторая - неэффективность, вызванную зависимостями в коде, а третья - потерю производительности, вызванную передачей данных.
	%Ими также как и в \#LINK\# исследуется возможность предсказания данных характеристик приложения на больших конфигурациях, построенного на основе запусков на малых конфигурациях. \#мб результаты убрать\# Модель тестируется с помощью приложений из CORAL(HACC, Nekbone, AMG2013) и приложения AVBP. Запуски HACC и Nekbone проводятся в условиях сильной масштабируемости, а AMG2013 и AVBP - в условиях слабой. Получившиеся значения относительных ошибок варьируются от 0.01\% до 27.19\%.

	Существует большое число работ направленых на исследование и предсказание масштабируемости приложений на суперкомпьютерах, но встречаются и такие, которые используют для запуска параллельных приложений отдельные узлые, небольшие вычислетельные системы, грид-системы, платформы для облачных вычислений.

	Все исследования можно разделить на две группы, первая объединяется в себе те, что ставят перед собой цель используя запуски на малых конфигурациях экстраполировать их на большие, вторая же состоит из тех работ, что основываясь на результатах запусков, равномерно распределённых по пространству параметров, пытаются интерполировать их на всё пространство параметров.

	Наиболее распространёнными для предсказания масшатибуемости являются подходы, использующие аппарат линейной регрессии, методы машинного обучения и нейронные сети, а также симуляцию исполнения программы или коллаборативную фильтрацию. Все они будут рассмотрены в следующей части этой главы.

	\section{Линейная регрессия}
		В статье \cite{log_main} предложены 3 техники предсказания масшатабиремости параллельных программ, в основе которых лежит подбор коэффициентов линейной регрессии. Эти техники испольльзуют набор запусков приложений на небольшом количестве процессов с разными входными парамерами, чтобы предсказать производительность на большом количестве процессов. Первая техника является идейно самой простой: результаты тестовых запусков используются для подбора коэффициентов регрессии, а затем результаты экстраполируются на конфигурации большого размера. Две другие техники являются усовершенствованием первой, они обе рассматривают время вычислений и время коммуникаций отдельно, но если вторая техника основывается на временах вычислений и коммуникаций полученных от каждого из процессов, выбирается максимальный по времени вычислений процесс и используется его же время коммуникаций, то третья техника основывается на определении времени коммуникаций и вычислений на критическом пути, самой длинной последовательности выполнения программы без блокировок.

		В статье рассматривается сильная масштабируемость, где это возможно, то есть, где задача помещается в память при использовании малого количества процессов, или гибрид сильной и слабой масштабируемостей. Строятся предсказания времени выполнения программы на большом количестве процессов, используя несколько запуской той же программы на меньшем количестве. Для оценки качества предсказаний используется относительная ошибка.	Из-за этого необходимо использовать приближение в логарифмическом масштабе, а с учётом того, что авторами используется линейная регрессионная модель, формулу предиктора можно записать в виде:
		\begin{equation}
		\log_2{(T)} = \sum_{i=1}^{n}{\beta_i\log_2{(x_i)}} + g(q) + error
		\end{equation}
		Где для выражения, объясняющего вклад количества используемых процессов используется либо линейное, либо квадратичное выражение:
		\begin{equation}
		g(q) = \gamma_0 + \gamma_1\log_2(q) + [\gamma_2log_2^2(q)]
		\end{equation}
		Несмотря на наличие логарифмов, статистически это всё ещё линейная модель, поскольку она линейна относительно неизвестных параметров.


		% \(p\) процессах, используя несколько запусков той же программы на \(q\) процессах, где \(q \in \{2,\ldots, p_0\},\,p_0 < p\), для произвольного \(p\). Предиктор реального времени исполнения \(T\) представляет собой функцию зависящую от входных параметров \((x_1, x_2, \ldots, x_n)\) и количества используемых процессов \(q\):
		% \begin{equation}\label{lin_formula}
		% \hat{T} = F(x_1, x_2, \ldots, x_n, q)
		% \end{equation}
		% Для оценки качества предсказаний используется относительная ошибка, вычисляемая по формуле:
		% \begin{equation}
		% E = \frac{|T - \hat{T}|}{T}
		% \end{equation}
		% Из-за того что используется относительная ошибка для оценки модели, \(F\) должная приближать \(T\) в логарифмическом масштабе, а с учётом того, что авторами используется линейная модель, формула \ref{lin_formula} преобразуется в
		% \begin{equation}
		% \log_2{(T)} = \sum_{i=1}^{n}{\beta_i\log_2{(x_i)}} + g(q) + error
		% \end{equation}
		% , где для выражения, объясняющего вклад количества используемых процессов используется либо линейное, либо квадратичное выражение:
		% \begin{equation}
		% g(q) = \gamma_0 + \gamma_1\log_2(q) + [\gamma_2log_2^2(q)]
		% \end{equation}
		% Несмотря на наличие логарифмов, статистически это всё ещё линейная модель, поскольку она линейна относительно неизвестных параметров.

		Для различных приложений медианная ошибка предсказаний изменяется от 1\% до 92\% в случае с первой техникой и от 7\% до 67\% для второй и третьей техник.

		Используемая модель обладает несколькими недостатками: не всегда возможно разделить время коммуникаций и вычислений, а чтобы это сделать, возможно, необходимо обладать знаниями об исходном коде программы или быть способным его модифицировать, поэтому использование второй и третьей техник не всегда представляется возможным. При использовании этих техник также неясно, какой вид для функции \(g(q)\) следуеть использовать. Также авторами метода прогнозирования предполагалось, что исследуемые задачи обладают хорошей вычислительной сбалансированностью, но далеко не все параллельные приложения отвечают этому предположению.

		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Такой же подход, использование линейной регрессии и логарифмической шкалы, применяется в работе \cite{focused_regression}. В ней авторы ставят перед собой задачу разработать модель, позволяющую находить конфигурации запуска, так чтобы они находились на кривой постоянного времени работы приложения, если в качестве пространства параметров конфигураций рассматривать размер задачи и количество процессов, на которых будет запущено приложение. Для построения модели используется информация о том, есть ли связь между параметрами запуска приложения, специфицируется ли при запуске процессорная сетка, позволяющая контролировать распределение данных, и набор запусков приложения на небольшим количестве процессов. Экспериментальная проверка построенной модели на семи суперкомпьютерных приложениях позволила предсказать неизвестные значения параметров так, что медианная ошибка предсказаний получилась меньше 13\%.

		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Подход предложенный в \cite{analytic_func} отличается от всех остальных прежде всего тем, что строится не просто предсказания значений той или иной динамической характеристики параллельной программы, а предлагается функция, описывающая изменение этой характеристики и зависящая от параметров запуска. Такой подход находит своё применение, когда необходимо оценить ассимптотику поведения динамических характеристик, но построить точную аналитическую модель, предсказывающую их, является затруднительной задачей.
			
		На первом этапе работы собирается такая информация как время исполнения, значения различных счётчиков производительности, включая аппаратные счётчики(количество операций с чистами с плавающей точкой), программые счётчики(количество байт, которые MPI функции отправили и приняли). Чтобы обеспечить статистически значимый набор данных о производительности, измерения, для одних их тех же конфигураций запуска проводятся несколько раз.\#LINK СЮДА \#\label{several_times_test} С помощью профайлера Scalasca в коде программы выделяются фрагменты, так называемые ядра, к которым можно отнести, вызовы MPI функций, наиболее вычислетильно интенсивные участи кода. Далее используется регрессия для получения грубой модели производительности для каждого ядра. В качестве моделей рассматриваются выражения вида:
		\begin{equation}
		f(p) = \sum \limits_{k=1}^{n} c_k \cdot p^{i_k} \cdot \log_2^{j_k}(p),\; i_k \in I,\; j_k \in J 
		\end{equation}, где \(I\) и \(J\) заданные заранее множества. Эти модели затем проходят итеративный процесс уточнения, во время которого методами регрессионного анализа подбираются наиболее оптимальные значения \(c_k\) для всевозможных значений \(n,\;i_{k},\;j_{k}\), пока качество модели не достигнет точки насыщения. Собранные результаты запусков разделяются на две группы: в первой находятся запуски на небольших конфигурациях, на них основывается работа по подбору коэффициентов, во второй - запуски на конфигурациях большего размера, именно на них поведение приложений представляет наибольший интерес, использующиеся для оценки качетсва предсказаний модели. Если степень точности предсказаний недостаточна для получения действенной рекомендации измерения производительности, то исследуемые ядра могут быть дополнительно уточнены с помощью более подробного инструментария. Разработанный подход тестировался на приложениях SWEEP3D, MILC и предсказал ассимптотики масштабируемости в точности согласующиеся с ранее созданными точными моделями. Для приложения HOMME, масшатибуемость которого раннее не исследовалась и поэтому такой точной модели не было, предложенный авторами подход позволил обнаружить плохую масштабируемость, что полностью подтвердилось результатами проведённых экспериментов.

		Стоит отметить, что множества \(I\) и \(J\) задаются для каждого приложения по-своему, а количество и значения элементов в них устанавливается исходя только из логических соображений, что не удовлетворяет требованиям универсальности, ведь результаты предсказаний напрямую зависят от человека, исследующего характеристики приложения и задающего эти множества.



	\section{Методы машинного обучения}
		Методы машинного обучения широко применяются для предсказания производительности параллельных приложений, так как построение точной аналитической модели приложения часто является очень затруднительным, а сами модели не способны уловить сложные аспекты взаимодействия между архитектурой суперкомпьютера и исследуемыми программами.

		В статье \cite{ML_SMG2000} трёхслойная полносвязная нейронная сеть прямого распространения с сигмоидой в качестве функции активации используется для предсказания времени работы приложения SMG2000. В процессе исследований авторы работы сталкнулись с двумя проблемами из-за которых средняя ошибка предсказаний даже при использовании 10 тысяч запусков, равномерно распределённых по пространству параметров, в качестве обучающего множества, превосходит 15\%. Первая из проблем - это значительные шумы в результатах проведённых запусков, проявляющиеся в значительных просадках производительности. Они, например, могут возникать из-за работы операционной системы, использующей ресурсы системы совместно с потоками исполнения приложения. В качестве способа преодоления этой проблемы авторами было выбрано резервирование, как минимум одного процесса на узле на нужды ОС. Вторая проблема является более серьёзной и не так просто преодолимой. Это ориентированность алгоритма подбора весов в нейронной сети на минимизацию среднего квадрата ошибки, в то время как качество предсказания оценивается по вычислениям относительных ошибок. \#LINK сюда когда буду говорить про ошибки!!\#
		Чтобы исправить это, понадобилось применить техники стратификации выборки с применением весов и беггинг для обучения ансамблей моделей и дальнейшего усреднения прогнозов. После осуществления вышеописанных изменений качество предсказаний значительно возросло, теперь при использовании 500 запусков, средняя ошибка предсказаний не превышает 12\%, однако при увеличении размера обучающей выборки в 5 раз, до 2500 запусков, авторы получили уменьшение средней ошибки до 6,5\%, что уже является достаточно высокой точностью.

		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Примененеие нейронных сетей не ограниченно предсказаниями производительности на классических HPC системых, так авторы \cite{ML_Grid} используют технологии машинного обучения для предсказания времени работы научных приложений состоящих из нескольких подзадач со сложными внутренними зависимостями на Grid системах. Моделирование и предсказание времён исполнения таких приложений очень сложно из-за распределения и параллельного исполнения подзадач на столь разнородной системе и динамического поведения общих Grid ресурсов. Ошибка предсказаний рассматриваемой в работе трёхслойная нейронной сети с радиально-базисной функцией, в качестве функции автивации, в среднем не превышает 12\%, но стоит отметить, что для обучения нейронной сети потребовалось 10000 запусков рассмативаемых в статье приложений.

		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Нейронную сеть такой же конфигурации, как в \cite{ML_SMG2000}, авторы \cite{ML_PROC_KERN} используют для предсказания наиболее оптимальных параметров запусков приложений на SMP системах. Нейронная сеть используется для поиска этих самых параметров, в качестве параметров рассматриваются количество процессоров и количество используемых ядер на одном процессоре. Поиск оптимальной конфигурации необходим, так как использование оптимальных параметров позволяет не только сократить время вычислений и, как следствие, увиличить производительность, но и уменьшить энергопотребление. Проведённые авторами эксперименты показали, что используемая нейросеть позволяет достичь медианной ошибки предсказаний времени 7.5\% (для оценки используются времена на предлодложенной нейростетью конфигурации и оптимальной конфигурации, найденной полным перебором по всем возможным).

	\section{Симуляция исполнения программы}
		Подход с использованием симуляции исполнения приложений является наиболее сложным в реализации и часто требует в своей работе наличие информации о структуре программы и подробных технических характеристик HPC системы. Но не смотря на это подобные подходы встречаются.

		Так описанный в статье \cite{simulation_FASE} фреймворк FASE (The Fast and Accurate Simulation Environment) позволяет проводит симуляцию исполнений приложений на HPC системах. FASE предоставляет инструментарий для оценки производительности виртуально-прототипированных систем для своевременного и экономически эффективного определения идеальной конфигурации системы для конкретного набора приложений. Работа вреймворка состоит из двух этапов: сначала с помощью встроенных инструментов и методов собирается некоторая характеристика рассматриваемого приложения, далее вводятся параметры системы (тип коммуникационной сети, сетевой протокол, информация об используемых процессорах, оперативной памяти),	то есть создаётся некоторая модель системы. Если рассматривается производительность приложения на уже существующей системе и известны некоторые её характеристики, например, пропускная способность или среднее время задержки сети, то добавлении этой информации на втором этапе, позволит сделать предсказания FASE более точными. Полученные относительные ошибки моделируемого времени выполнения приложения в большинстве случаев не превосходят 10\% для бенчмарка Sweep3D и 1\% для перемножения матриц (корректность проверяется посредством моделирования исполнения приложений на существующих системах и сравнения с результатами реальных запусков на них).
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		Также существует техника детерминированного воспроизведения приложения, предложенная в \cite{representative_replay}. Она лежит в основе работы среды PHANTOM, реализованной авторами статьи. PHANTOM позволяет предсказать производительность и время исполнения приложения на конфигурации с большим количеством процессов использую множественные запуски того же приложения, но на конфигурациях меньшего размера. Для построения прогноза производительности используется подход симуляции на основе трассировки. Общую схему работы этой среды можно описать так: вычисления и коммуникации разделяются, собираются их трассы, времена последовательных вычислений измеряются для каждой отдельной группы процессов путём детерминированного воспроизведения процесса выполнения приложения, после этого разработанный авторами симулятор SIM-MPI по собранным трассам, полученному на предыдущем этапе времени вычислений и параметрам сети целевой системы предсказывает поведения различные операций коммуникации и время работы всего приложения.

		Для тестирования PHANTOM использовались шесть традиционных HPC платформ с различными конфигурациями системы %, Nebulae, Dawning, DeepComp-F, DeepComp-B, Explorer и Explorer-100 
		и одна платформа облачных вычислений.% Amazon EC2. 
		Рассматривался большой набор бенчмарков: 6 ядер из NPB, 8 приложений из SPEC MPI2007, ASCI Sweep3D и NWChem. Максимальная относительная ошибка для PHANTOM на классических системах не превосходит 10\%, а для Amazon EC2 \- 7\%.

	\section{Коллаборативная фильтрация}
		Авторы \cite{UV_matrix} используют подход, основанный на коллаборативной фильтрации и \(UV\) факторизации матрицы, для предсказания времён исполнения параллельных приложений на гетерогеный системах. Коллаборативная фильтрация хорошо себя зарекомендовал и широко используется в рекомендательных системах для построения прогнозов. Основная идея предложенного подхода состоит в том, чтобы использовать собранные профили выполненных заданий для данного типа приложения в качестве набора обучающих данных, а затем построить специальную матрицу для прогнозирования производительности на новой конфигурации физических ресурсов. Количество строк в этой матрице равно количеству проведённых тестированний исследуемой программы, столбцами являются как параметры запуска программы, такие как количество доступной памяти, количество процессов, на которых исполняется программа, так и значения динамических характеристик исполнения программы, полученные после её завершения, в качестве прогнозируемых характеристик в работе рассматриваются минимальное, среднее и максимальное времена исполнения приложения на нескольких запусках с идентичными конфигурациями. Чтобы предсказать значения этих характеристик в интересуемой конфигурации необходимо дополнить матрицу ещё одной строкой, заполнить в ней первые ячейки, отвечающие за параметры запуска, и произвести \(UV\) факторизацию полученной матрицы. После перемножения \(U\) и \(V\) результирующая матрица будет "<ближе"> всего к изначальной, в качестве меры "<близости"> используется среднеквадратичная ошибка, а незаполненный ранее ячейки будут содержать предсказанные значения времён исполнения.

		Для запусков приложений использовалась платформа для параллельных вычислений Apache Spark, время исполнения предсказывалось для трёх приложений: Shapelet Finding, Common Neighbor и WordCount. При использовании 70\% от всех конфигураций в качестве тестовой выборки среднее значение ошибки по трём приложениям не превосходит 20\%, при увеличении количества тестовых конфигураций до 90\% значение средней ошибки снижается до 8-12\%.

		Чтобы предложенный метод был применим, то есть давал точные прогнозы, необходимо, чтобы исходная таблица обладала большим количеством строк и столбцом, то есть было проведено много тестирований программы и были доступны большие наборы параметров запуска программы и динамических характеристик исполнения.

	\section{Сказать про Кристинину работу}

	ЕЩЁ ЧТО-ТО
	
	//Комментарий: этот абзац вынесу в обзорную часть статьи, в подраздел с обзором работы Кристины
	Альтернативный, использованию логарифмической шкалы, способ - использование регрессионной модели с весами, применяется в \cite{Kazmina_DIPLOMMMM}, где под весом некоторого тестового запуска подразумевается количество его экземпляров, которые будут входить в итоговый сформированный набор запусков, по которым строится аппроксимация. Добавление весов направленно на устранение двух возможных причин увеличения ошибок предсказания: минимизацию абсолютных ошибок вместо относительных во время регрессии и одинаковую значимость ошибок для всех размеров конфигурации при действительно важности результатов предсказания только для конфигураций большего размера. Данный метод позволил уменьшить средние и медианные относительные ошибки предсказаний для всех рассматриваемых в \cite{KRISININ_DIPLOM} приложений.% много копипасты в этом абзаце



%\clearpage

